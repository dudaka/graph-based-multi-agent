{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8590689,"sourceType":"datasetVersion","datasetId":5138476}],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n# %pip install -U bitsandbytes\n%pip install -U transformers\n%pip install -U peft\n%pip install accelerate\n!pip install -i https://pypi.org/simple/ bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-06-25T12:44:14.798941Z","iopub.execute_input":"2024-06-25T12:44:14.799685Z","iopub.status.idle":"2024-06-25T12:45:20.168803Z","shell.execute_reply.started":"2024-06-25T12:44:14.799652Z","shell.execute_reply":"2024-06-25T12:45:20.167669Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from transformers import (\n    AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline,\n    MBartForConditionalGeneration, MBart50TokenizerFast,\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    logging,\n)\nfrom peft import (\n    LoraConfig,\n    PeftModel,\n    prepare_model_for_kbit_training,\n    get_peft_model,\n    PeftConfig,\n    PeftModel,\n    AutoPeftModelForCausalLM\n)\nimport os, torch\n# from datasets import load_dataset\nimport time","metadata":{"execution":{"iopub.status.busy":"2024-06-25T12:45:20.171040Z","iopub.execute_input":"2024-06-25T12:45:20.171333Z","iopub.status.idle":"2024-06-25T12:45:38.804284Z","shell.execute_reply.started":"2024-06-25T12:45:20.171305Z","shell.execute_reply":"2024-06-25T12:45:38.803328Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-06-25 12:45:26.055196: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-25 12:45:26.055294: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-25 12:45:26.194818: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"lang_detect_name = 'qanastek/51-languages-classifier'\nlang_detect_tokenizer = AutoTokenizer.from_pretrained(lang_detect_name)\nlang_detect_model = AutoModelForSequenceClassification.from_pretrained(lang_detect_name).to('cuda:0')\nclassifier = TextClassificationPipeline(model=lang_detect_model, tokenizer=lang_detect_tokenizer)\n\ntranslate_name = \"facebook/mbart-large-50-many-to-many-mmt\"\ntranslate_model = MBartForConditionalGeneration.from_pretrained(translate_name).to('cuda:0')\ntranslate_tokenizer = MBart50TokenizerFast.from_pretrained(translate_name)\n\n# Load base model(Zephyr-7B 7B)\nbnb_config = BitsAndBytesConfig(  \n    load_in_4bit= True,\n    bnb_4bit_quant_type= \"nf4\",\n    bnb_4bit_compute_dtype= torch.bfloat16,\n    bnb_4bit_use_double_quant= False,\n)\n\n# gallantVN/zephyr-chat-pizza-1\nchat_tokenizer = AutoTokenizer.from_pretrained(\"gallantVN/zephyr-chat-pizza-1\")\nchat_model = AutoPeftModelForCausalLM.from_pretrained(\n    \"gallantVN/zephyr-chat-pizza-1\",\n#     low_cpu_mem_usage=True,\n    return_dict=True,\n    quantization_config=bnb_config,\n    torch_dtype=torch.bfloat16,\n    device_map=\"auto\",\n    trust_remote_code=True,)","metadata":{"execution":{"iopub.status.busy":"2024-06-25T12:45:38.805458Z","iopub.execute_input":"2024-06-25T12:45:38.806171Z","iopub.status.idle":"2024-06-25T12:55:54.383336Z","shell.execute_reply.started":"2024-06-25T12:45:38.806145Z","shell.execute_reply":"2024-06-25T12:55:54.382573Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/398 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27b3a324d3af43e19c47b8d73261d15c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c014b38dbcc24e698aa31a528afc8663"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"579b12278595493780d7bb0405dd1757"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d8a8ecd452a459b8d15e6848464e02f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.63k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d310ba3da2f4a00922c065ecdd33b8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e3e187bfdf441e39c1893db61333dac"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.43k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d14de1b88d9045269d6373a5f7375f45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58a4aa823aee4c79acdddae523c6e31b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/261 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d8505ac517f4398aa4c883665751018"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/529 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cab12fc82e2847168baf23504e46bea9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82694a961a0047a48a625297fb73e7c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"659b5e760ca04efb851dbd7291f60643"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.48k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a19a2191d5c74c719a63e8cd6002d731"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5bc814493e14d33bc3bc1e998ea28cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05fb32539e73441b92fc33dcf1ad4c8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/510 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4f6a8cb1fff420bae2d052fbb05f409"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/675 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd46ab42a21e4721b467451884a825f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/638 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6de4125864f54fa68c779c95e419c615"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"caf184826efd4ff29d5f7f412307ac4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9499c59468de449e80044a2396da0ee7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00008.safetensors:   0%|          | 0.00/1.89G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"532b5bb923914c038ad2c8fae84577a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58bb87d7565c4280a4fa3ca924b7a149"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2de35879abd140c3ac1ab5a95fc0a60b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f860bfe3142d45bca6d917e7c484864a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47bc3161270549e4be26a6e277ec16bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00006-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"375ecf52a03344dbb59431ef6bcd1911"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00007-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0c5a343559a4ca2bda31a78a19f165f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00008-of-00008.safetensors:   0%|          | 0.00/816M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbda24946f7641509f70ba39cfb3ae10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7122e633bb034fb99b9829836f57ba2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39b873fb8e3e4064816d14e30a1fa494"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/302M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1b5dd763a254546bbb36d19f3af98bb"}},"metadata":{}}]},{"cell_type":"code","source":"def lang_detect(prompt):\n    \"\"\"\n    Dectect which language that user used for chat\n\n    Returns:\n        Language tag\n    \"\"\"\n    res = classifier(prompt)\n    tag = res[0][\"label\"].replace(\"-\", \"_\")\n    return tag\n\ndef translate(tag_inp, tag_out, prompt):\n    \"\"\"\n    Translate from user's language to English and vice versa.\n\n    Returns:\n        English prompt or answer in user's language.\n    \"\"\"\n    translate_tokenizer.src_lang = tag_inp\n    encoded_prompt = translate_tokenizer(prompt, return_tensors=\"pt\").to('cuda:0')\n    generated_tokens = translate_model.generate(\n        **encoded_prompt,\n        forced_bos_token_id=translate_tokenizer.lang_code_to_id[tag_out]\n    )\n    ans = translate_tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n    return ans[0]\n\ndef assistant(tag_inp, tag_out, ques):\n    dict_tag = {\n        \"en\": \"XX\", # english\n        \"es\": \"XX\", # spanish\n        \"fr\": \"XX\", # french\n        \"ja\": \"XX\", # japanese\n        \"nl\": \"XX\", # dutch\n    }\n    try:\n        split_tag_inp = tag_inp.split(\"_\")\n        tag_inp = f\"{split_tag_inp[0]}_{dict_tag[split_tag_inp[0]]}\"\n#         print(tag_inp)\n    except: pass\n    \n    if tag_inp == \"en_XX\":\n        que = ques\n        # chat model\n        messages.append({\"role\":\"user\", \"content\": que})\n        tokenized_chat = chat_tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\")\n        outputs = chat_model.generate(tokenized_chat.to('cuda:1'), max_new_tokens=128)\n        ans = chat_tokenizer.decode(outputs[0])\n        anss = ans.split(\"\\n<|assistant|>\\n\")[-1].split(\"</s>\")[0]\n        \n        # output\n        messages.append({\"role\": \"assistant\", \"content\": anss})\n        print(\"\\nAssistant:\", anss)\n        ends = time.time() - start\n        print(ends)\n    else:\n        que = translate(tag_inp, tag_out, ques)\n        tag_out = tag_inp\n        tag_inp = \"en_XX\"\n        \n        # chat model\n        messages.append({\"role\":\"user\", \"content\": que})\n        tokenized_chat = chat_tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\")\n        outputs = chat_model.generate(tokenized_chat.to('cuda:1'), max_new_tokens=128)\n        ans = chat_tokenizer.decode(outputs[0])\n        ans = ans.split(\"\\n<|assistant|>\\n\")[-1].split(\"</s>\")[0]\n        anss = translate(tag_inp, tag_out, ans)\n\n        # output\n        messages.append({\"role\": \"assistant\", \"content\": anss})\n        print(\"\\nAssistant:\", anss)\n        ends = time.time() - start\n        print(ends)","metadata":{"execution":{"iopub.status.busy":"2024-06-25T12:55:54.384930Z","iopub.execute_input":"2024-06-25T12:55:54.385420Z","iopub.status.idle":"2024-06-25T12:55:54.399837Z","shell.execute_reply.started":"2024-06-25T12:55:54.385385Z","shell.execute_reply":"2024-06-25T12:55:54.398945Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"torch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)","metadata":{"execution":{"iopub.status.busy":"2024-06-25T12:55:54.402447Z","iopub.execute_input":"2024-06-25T12:55:54.402906Z","iopub.status.idle":"2024-06-25T12:55:54.446586Z","shell.execute_reply.started":"2024-06-25T12:55:54.402848Z","shell.execute_reply":"2024-06-25T12:55:54.445857Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"messages = [\n    {\n        \"role\": \"system\",\n        \"content\": \"You are a friendly chatbot assistant for ordering pizza at KinPizza.\",\n    },\n#     {\"role\": \"user\", \"content\": \"Hi, I'm interested in ordering a pizza from KinPizza. What types of pizzas do you offer?\"},\n ]\n\nans = ''\nwhile True:\n    que = input(\"User: \")\n    if que == \"Bye\":\n        break\n    \n    # find lang tag\n    start = time.time()\n    tag_inp = lang_detect(que)\n    split_tag_inp = tag_inp.split(\"_\")\n    tag_inp = f\"{split_tag_inp[0]}_{split_tag_inp[1]}\"\n    tag_out = \"en_XX\"\n    \n    # assis\n    assistant(tag_inp, tag_out, que)","metadata":{"execution":{"iopub.status.busy":"2024-06-25T12:59:25.706353Z","iopub.execute_input":"2024-06-25T12:59:25.706715Z","iopub.status.idle":"2024-06-25T13:01:34.038965Z","shell.execute_reply.started":"2024-06-25T12:59:25.706688Z","shell.execute_reply":"2024-06-25T13:01:34.038210Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdin","text":"User:  Hi, I'm interested in ordering a pizza from KinPizza. What types of pizzas do you offer?\n"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nAssistant: Welcome to KinPizza! We have a wide variety of pizzas to choose from. Our most popular choices include:\n Cheese Pizza: A classic combination of cheese and cream sauce, served with honey.\n Chicken BBQ Pizza: A savory blend of cheese, tomato sauce, chicken, onion, bell pepper, and BBQ sauce.\n Veggie Pizza: A healthy option with cheese, tomato sauce, onion, bell pepper, mushroom, and black olive.\n Sausage Pizza: A meaty delight with cheese, tomato sauce, and sausage.\n11.134695768356323\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  tôi muốn đặt cheese pizza\n"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nAssistant: Một lựa chọn tuyệt vời! Pizza phô mai của chúng tôi có 3 kích cỡ: Trung (24cm), to (34cm), và to (42cm).\n5.322746753692627\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  Donnez-moi une taille moyenne\n"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nAssistant: Nos pizzas moyennes ont un diamètre de 24 cm.\n3.948745012283325\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  nó có giá bao nhiêu?\n"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nAssistant: Giá của pizza phô mai trung bình là 179,000 VND.\n4.7033655643463135\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  Thank you, here is my phone number:0919512867\n"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nAssistant: Perfect! Your total cost is 179,000 VND. Your pizza will be delivered within 30 minutes.\n5.364912986755371\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User:  Bye\n"}]},{"cell_type":"code","source":"messages","metadata":{"execution":{"iopub.status.busy":"2024-06-25T13:02:24.651451Z","iopub.execute_input":"2024-06-25T13:02:24.651804Z","iopub.status.idle":"2024-06-25T13:02:24.658695Z","shell.execute_reply.started":"2024-06-25T13:02:24.651775Z","shell.execute_reply":"2024-06-25T13:02:24.657812Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[{'role': 'system',\n  'content': 'You are a friendly chatbot assistant for ordering pizza at KinPizza.'},\n {'role': 'user',\n  'content': \"Hi, I'm interested in ordering a pizza from KinPizza. What types of pizzas do you offer?\"},\n {'role': 'assistant',\n  'content': 'Welcome to KinPizza! We have a wide variety of pizzas to choose from. Our most popular choices include:\\n Cheese Pizza: A classic combination of cheese and cream sauce, served with honey.\\n Chicken BBQ Pizza: A savory blend of cheese, tomato sauce, chicken, onion, bell pepper, and BBQ sauce.\\n Veggie Pizza: A healthy option with cheese, tomato sauce, onion, bell pepper, mushroom, and black olive.\\n Sausage Pizza: A meaty delight with cheese, tomato sauce, and sausage.'},\n {'role': 'user', 'content': 'I wanted to put cheese pizza.'},\n {'role': 'assistant',\n  'content': 'Một lựa chọn tuyệt vời! Pizza phô mai của chúng tôi có 3 kích cỡ: Trung (24cm), to (34cm), và to (42cm).'},\n {'role': 'user', 'content': 'Give me an average size'},\n {'role': 'assistant',\n  'content': 'Nos pizzas moyennes ont un diamètre de 24 cm.'},\n {'role': 'user', 'content': 'How much does it cost?'},\n {'role': 'assistant',\n  'content': 'Giá của pizza phô mai trung bình là 179,000 VND.'},\n {'role': 'user', 'content': 'Thank you, here is my phone number:0919512867'},\n {'role': 'assistant',\n  'content': 'Perfect! Your total cost is 179,000 VND. Your pizza will be delivered within 30 minutes.'}]"},"metadata":{}}]}]}